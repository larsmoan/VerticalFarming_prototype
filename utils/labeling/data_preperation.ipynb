{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is a tool for splitting and preparing the data from the StrawDI dataset \n",
    "\n",
    "#Task 1 : convert the label images to txt files for training with yolov7\n",
    "#Task2 : extract the bounding boxes from the images and create new ones - for training ripeness and weight models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/larsmoan/Documents/Datasets/StrawDI_Db1/val/label/\"\n",
    "annotations_path = \"/Users/larsmoan/Documents/Datasets/StrawDI_Db1/val/annotations/\"\n",
    "#NB! This script will create another copy of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pascal_Voc bb to Yolo\n",
    "def pascal_voc_to_yolo(x1, y1, x2, y2, image_w, image_h):\n",
    "    return [((x2 + x1)/(2*image_w)), ((y2 + y1)/(2*image_h)), (x2 - x1)/image_w, (y2 - y1)/image_h]\n",
    "\n",
    "def yolo_to_pascal_voc(x_center, y_center, w, h,  image_w, image_h):\n",
    "    w = w * image_w\n",
    "    h = h * image_h\n",
    "    x1 = ((2 * x_center * image_w) - w)/2\n",
    "    y1 = ((2 * y_center * image_h) - h)/2\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def create_annotations(label_path, label_filename, annotation_path):\n",
    "\n",
    "    label = cv2.imread(label_path+label_filename)\n",
    "\n",
    "    #Check if the label is a valid image\n",
    "    if label is None:\n",
    "        print(\"Label is not a valid image\")\n",
    "        return\n",
    "\n",
    "    #Convert to grayscale\n",
    "    label_copy = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    #Opening txt file for annotations - corresponding name to label\n",
    "    f = open(annotation_path+label_filename[:-4]+\".txt\", \"w\")\n",
    "\n",
    "    #Getting the maximal value in the grayscale picture - corresponds to number of berries\n",
    "    max_val = np.amax(label)\n",
    "\n",
    "    #Doing it for more than one gray value, i.e all the berries\n",
    "    for i in range(1,max_val+1):\n",
    "        white_pixels_x = []\n",
    "        white_pixels_y = []\n",
    "\n",
    "        \"\"\" for row in range(label.shape[0]):\n",
    "            for col in range(label.shape[1]):\n",
    "                if label_copy[row][col] == i:\n",
    "                    white_pixels_y.append(row)\n",
    "                    white_pixels_x.append(col) \"\"\"\n",
    "\n",
    "        #Using numpy to do the search, way to slow with double for loop\n",
    "        white_pixels_y = np.where(label_copy == i)[0]\n",
    "        white_pixels_x = np.where(label_copy == i)[1]\n",
    "\n",
    "       \n",
    "        \n",
    "        #True if the lists contains elements\n",
    "        if white_pixels_x[0] and white_pixels_y[0]:\n",
    "            x_min = white_pixels_x.min()\n",
    "            x_max = white_pixels_x.max()\n",
    "            y_min = white_pixels_y.min()\n",
    "            y_max = white_pixels_y.max()\n",
    "\n",
    "            yolo_box = pascal_voc_to_yolo(x_min, y_min, x_max, y_max, label.shape[1], label.shape[0])\n",
    "        \n",
    "            #Writing the coordinates to the txt file\n",
    "            f.write('0' + ' ' + str(yolo_box[0]) + \" \" + str(yolo_box[1]) + \" \" + str(yolo_box[2]) + \" \" + str(yolo_box[3]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one creates all the annotations for the dataset - only run it once\n",
    "for filename in os.listdir(dataset_path):\n",
    "    create_annotations(dataset_path, filename, annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Create the subpictures that should be used for the second models\n",
    "\n",
    "img_path = \"/Users/larsmoan/Documents/Datasets/StrawDI_Db1/val/img/\"\n",
    "annotations_path = \"/Users/larsmoan/Documents/Datasets/StrawDI_Db1/val/annotations/\"\n",
    "sub_images_path = \"/Users/larsmoan/Documents/Datasets/StrawDI_Db1/val/sub_images/\"\n",
    "#Getting the boxes from the annotations folder\n",
    "\n",
    "def create_sub_images(img_path, img_filename, annotations_path, annotation_filename, sub_img_path):\n",
    "    img = cv2.imread(img_path+img_filename)\n",
    "    image_w = img.shape[1]\n",
    "    image_h = img.shape[0]\n",
    "\n",
    "    #Reading the boxes from the annotations file\n",
    "    f = open(annotations_path+annotation_filename, \"r\")\n",
    "    lines = f.readlines()\n",
    "\n",
    "    boxes = []\n",
    "    for line in lines:\n",
    "        #Convert the boxes to pascal voc\n",
    "        box = line.split(\" \")\n",
    "        box = box[1:]\n",
    "        \n",
    "        #Convert the box to float\n",
    "        box = [float(i) for i in box]\n",
    "        boxes.append(box)\n",
    "\n",
    "    #Creating the sub images\n",
    "    for i in range(len(boxes)):\n",
    "        box = boxes[i]\n",
    "        box = yolo_to_pascal_voc(box[0], box[1], box[2], box[3], image_w, image_h)\n",
    "        sub_img = img[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "\n",
    "        #Saving the sub images\n",
    "        cv2.imwrite(sub_img_path+img_filename[:-4]+\"_\"+str(i)+\".png\", sub_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one creates all the sub images for the dataset - only run it once per folder\n",
    "for img_filename in os.listdir(img_path):\n",
    "    create_sub_images(img_path, img_filename, annotations_path, img_filename[:-4]+\".txt\", sub_images_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
